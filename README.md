# local_llm_app
Ollama llm to be run with simple avatar (budget clippy)
